"""
Complete GRPO-GRPO-P Integration System
Orchestrates the entire hybrid recommendation framework
"""

import sys
import os
import logging
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import json
import re
import pandas as pd

# Add src to path for imports
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from src.data.news_collector import NewsCollector
from src.processing.text_processor import TextProcessor
from src.processing.recommendation_engine import UserProfile
from src.agents.grpo_agent import GRPOPopulation, MarketState
from src.agents.grpo_p_agent import GRPOPAgent, UserFeedback, PersonalizedAction
from src.agents.arbitration_controller import ArbitrationController, ArbitrationContext, BlendedRecommendation
from src.agents.arbitration_controller import (
    EnhancedRecommendation, CompanyInfo, ArticleSummary, MarketAnalysis, 
    PolicyImpact, RecommendationStrategy
)

logger = logging.getLogger(__name__)

@dataclass
class SystemUser:
    """Enhanced user profile for the complete system"""
    user_id: str
    role: str  # entrepreneur, investor, business_owner, analyst
    sectors: List[str]
    location: str
    capital_range: str
    risk_appetite: str
    experience_level: str
    
    # System interaction preferences
    notification_frequency: str = "daily"  # daily, weekly, real_time
    preferred_explanation_level: str = "medium"  # brief, medium, detailed
    interface_complexity: str = "standard"  # simple, standard, advanced
    
    # Learning preferences
    learning_mode: bool = True  # Whether to actively learn from user
    feedback_enabled: bool = True  # Whether user provides explicit feedback
    exploration_tolerance: float = 0.3  # How much exploration user tolerates (0-1)

class HybridRecommendationSystem:
    """
    Complete GRPO-GRPO-P Hybrid Business Intelligence System
    Combines group consensus with personalized learning
    """
    
    def __init__(self, 
                 config_path: str = "config/config.json",
                 user_profiles_dir: str = "user_profiles",
                 enable_persistence: bool = True):
        """
        Initialize the complete hybrid recommendation system
        
        Args:
            config_path: Path to configuration file
            user_profiles_dir: Directory for storing user profiles
            enable_persistence: Whether to persist user learning
        """
        
        self.config_path = config_path
        self.user_profiles_dir = user_profiles_dir
        self.enable_persistence = enable_persistence
        
        # Initialize core components
        self.news_collector = None
        self.text_processor = None
        self.grpo_population = None
        self.arbitration_controller = None
        
        # User management
        self.active_users: Dict[str, SystemUser] = {}
        self.grpo_p_agents: Dict[str, GRPOPAgent] = {}
        
        # System state
        self.latest_market_state: Optional[MarketState] = None
        self.latest_processed_df: Optional[pd.DataFrame] = None
        self.system_performance_history = []
        
        # Initialize system
        self._initialize_system()
        
        logger.info("ðŸš€ Hybrid GRPO-GRPO-P Recommendation System initialized")
    
    def _initialize_system(self):
        """Initialize all system components"""
        
        try:
            # Load configuration
            with open(self.config_path, 'r') as f:
                config = json.load(f)
            
            # Initialize news collection
            try:
                from config.settings import Config
                api_key = Config.NEWSAPI_KEY or config.get('news_api_key', 'demo_api_key')
            except Exception:
                api_key = config.get('news_api_key', 'demo_api_key')

            self.news_collector = NewsCollector(api_key=api_key)
            
            # Initialize text processing
            self.text_processor = TextProcessor()
            
            # Initialize GRPO population
            available_sectors = ["technology", "finance", "energy", "healthcare", 
                               "retail", "manufacturing", "real_estate"]
            self.grpo_population = GRPOPopulation(
                population_size=15,
                sectors=available_sectors
            )
            
            # Initialize arbitration controller
            self.arbitration_controller = ArbitrationController(
                learning_rate=0.05,
                exploration_rate=0.1
            )
            
            # Create user profiles directory
            if self.enable_persistence:
                os.makedirs(self.user_profiles_dir, exist_ok=True)
            
            logger.info("âœ… All system components initialized successfully")
            
        except Exception as e:
            logger.error(f"âŒ Error initializing system: {e}")
            raise
    
    def register_user(self, user: SystemUser) -> str:
        """
        Register a new user with the system
        
        Args:
            user: User profile to register
            
        Returns:
            User ID for the registered user
        """
        
        # Store user profile
        self.active_users[user.user_id] = user
        
        # Initialize GRPO-P agent for this user
        agent_profile_path = None
        if self.enable_persistence:
            agent_profile_path = os.path.join(self.user_profiles_dir, f"{user.user_id}.json")
        
        self.grpo_p_agents[user.user_id] = GRPOPAgent(
            user_id=user.user_id,
            sectors=user.sectors,
            persistence_path=agent_profile_path
        )
        
        logger.info(f"ðŸ‘¤ Registered new user: {user.user_id} ({user.role})")
        logger.info(f"   Sectors: {user.sectors}")
        logger.info(f"   Risk appetite: {user.risk_appetite}")
        
        return user.user_id
    
    def get_recommendations(self, 
                          user_id: str,
                          max_recommendations: int = 3,
                          include_explanations: bool = True) -> List[BlendedRecommendation]:
        """
        Get personalized hybrid recommendations for a user
        
        Args:
            user_id: ID of the user requesting recommendations
            max_recommendations: Maximum number of recommendations to return
            include_explanations: Whether to include detailed explanations
            
        Returns:
            List of blended recommendations
        """
        
        if user_id not in self.active_users:
            raise ValueError(f"User {user_id} not found. Please register first.")
        
        user = self.active_users[user_id]
        grpo_p_agent = self.grpo_p_agents[user_id]
        
        # Get latest market data
        market_state = self._get_current_market_state()
        # Constrain population sectors to include user's sectors preferentially
        user_sectors = set(user.sectors)
        if user_sectors:
            # Temporarily bias GRPO agents towards user's sectors
            original_sector_sets = []
            for agent in self.grpo_population.agents:
                original_sector_sets.append(agent.sectors[:])
                # Keep intersection if any, else keep as-is
                intersect = [s for s in agent.sectors if s in user_sectors]
                if len(intersect) > 0:
                    agent.sectors = intersect
        
        # Get GRPO population consensus
        grpo_recommendation = self.grpo_population.get_consensus_recommendation(market_state)
        
        # Get personalized GRPO-P recommendation
        grpo_p_recommendation = grpo_p_agent.get_action(market_state)
        
        # Create arbitration context
        context = self._create_arbitration_context(user, market_state)
        
        # Arbitrate between GRPO and GRPO-P
        blended_recommendation = self.arbitration_controller.arbitrate(
            grpo_recommendation, grpo_p_recommendation, context
        )
        # If GRPO suggested a sector outside user preferences, steer to user sectors when possible
        if user_sectors and blended_recommendation.sector not in user_sectors:
            # Choose the closest sector from user list based on market sentiment
            best_user_sector = max(user_sectors, key=lambda s: market_state.sector_sentiments.get(s, -1.0))
            blended_recommendation.sector = best_user_sector
        
        # Risk-aware adjustment: for low-risk users, cap high risk unless confidence is very high
        if user.risk_appetite == "low" and blended_recommendation.risk_level == "high":
            if blended_recommendation.confidence < 0.75 or market_state.volatility > 0.5:
                blended_recommendation.recommendation_type = "monitor"
                blended_recommendation.risk_level = "moderate"
        
        # Enrich with item-level suggestions
        self._attach_item_level_recommendations(blended_recommendation)
        
        # Generate additional recommendations if requested
        recommendations = [blended_recommendation]
        
        if max_recommendations > 1:
            # Generate alternative recommendations with different strategies
            additional_recs = self._generate_diverse_recommendations(
                user, market_state, max_recommendations - 1
            )
            recommendations.extend(additional_recs)
        
        # Restore original agent sectors
        if user_sectors:
            for agent, orig in zip(self.grpo_population.agents, original_sector_sets):
                agent.sectors = orig
        
        logger.info(f"ðŸ“Š Generated {len(recommendations)} recommendations for {user_id}")
        
        return recommendations

    def _generate_diverse_recommendations(self, user: SystemUser, market_state: MarketState, count: int) -> List[BlendedRecommendation]:
        """Generate diverse recommendations using different strategies"""
        
        recommendations = []
        
        # Use different blending strategies for diversity
        blending_strategies = [
            "confidence_weighted",
            "user_experience_based", 
            "market_condition_adaptive",
            "dynamic_learned",
            "conservative_fusion"
        ]
        
        for i in range(count):
            # Get fresh recommendations
            grpo_rec = self.grpo_population.get_consensus_recommendation(market_state)
            grpo_p_rec = self.grpo_p_agents[user.user_id].get_action(market_state)
            
            # Modify sector for diversity
            available_sectors = list(market_state.sector_sentiments.keys())
            if available_sectors:
                grpo_rec.sector = available_sectors[i % len(available_sectors)]
            
            # Create context with different strategy
            context = self._create_arbitration_context(user, market_state)
            context.blending_strategy = blending_strategies[i % len(blending_strategies)]
            
            # Arbitrate
            blended = self.arbitration_controller.arbitrate(grpo_rec, grpo_p_rec, context)
            
            # Ensure diversity in recommendation type
            if i > 0:
                if blended.recommendation_type == recommendations[0].recommendation_type:
                    blended.recommendation_type = "monitor" if blended.recommendation_type == "invest" else "invest"
            
            # Add item-level recommendations
            self._attach_item_level_recommendations(blended)
            
            recommendations.append(blended)
        
        return recommendations

    def get_enhanced_recommendations(self, 
                                   user_id: str,
                                   max_recommendations: int = 5) -> List[EnhancedRecommendation]:
        """Get comprehensive, diverse recommendations with full evidence and reasoning"""
        
        if user_id not in self.active_users:
            raise ValueError(f"User {user_id} not found. Please register first.")
        
        user = self.active_users[user_id]
        market_state = self._get_current_market_state()
        
        # Generate diverse recommendations using different strategies
        recommendations = []
        strategies = list(RecommendationStrategy)[:max_recommendations]
        
        for i, strategy in enumerate(strategies):
            rec = self._generate_strategy_specific_recommendation(
                user, market_state, strategy, i, user_id
            )
            recommendations.append(rec)
        
        logger.info(f"ðŸš€ Generated {len(recommendations)} enhanced recommendations for {user_id}")
        return recommendations

    def _generate_strategy_specific_recommendation(self, 
                                                user: SystemUser,
                                                market_state: MarketState,
                                                strategy: RecommendationStrategy,
                                                index: int,
                                                user_id: str) -> EnhancedRecommendation:
        """Generate a recommendation using a specific strategy"""
        
        # Get base recommendations from different perspectives
        grpo_rec = self.grpo_population.get_consensus_recommendation(market_state)
        grpo_p_rec = self.grpo_p_agents[user_id].get_action(market_state)
        
        # IMPORTANT: Force the sector to be user's preferred sector
        user_sectors = user.sectors
        if user_sectors:
            # Use the first preferred sector (or cycle through them for diversity)
            selected_sector = user_sectors[index % len(user_sectors)]
            grpo_rec.sector = selected_sector
            grpo_p_rec.base_action.sector = selected_sector
        
        # Apply strategy-specific modifications (but keep the sector!)
        modified_grpo, modified_grpo_p = self._apply_strategy_modifications(
            grpo_rec, grpo_p_rec, strategy, user, market_state
        )
        
        # Create arbitration context
        context = self._create_arbitration_context(user, market_state)
        
        # Arbitrate with strategy-specific weights
        blended = self.arbitration_controller.arbitrate(modified_grpo, modified_grpo_p, context)
        
        # Generate comprehensive recommendation
        enhanced_rec = self._create_enhanced_recommendation(
            blended, strategy, user, market_state, index
        )
        
        return enhanced_rec

    def _apply_strategy_modifications(self, grpo_rec, grpo_p_rec, strategy, user, market_state):
        """Apply strategy-specific modifications to recommendations"""
        
        # IMPORTANT: Never change the sector - respect user's choice
        # The strategy should only affect risk, timing, and approach within the same sector
        
        if strategy == RecommendationStrategy.CONSERVATIVE_LONG_TERM:
            # Conservative: lower risk, longer horizon, same sector
            grpo_rec.risk_level = "low" if grpo_rec.risk_level == "high" else grpo_rec.risk_level
            grpo_rec.recommendation_type = "monitor" if grpo_rec.recommendation_type == "invest" else grpo_rec.recommendation_type
            
        elif strategy == RecommendationStrategy.AGGRESSIVE_SHORT_TERM:
            # Aggressive: higher risk, shorter horizon, same sector
            grpo_rec.risk_level = "high" if grpo_rec.risk_level == "low" else grpo_rec.risk_level
            grpo_rec.recommendation_type = "invest" if grpo_rec.recommendation_type == "monitor" else grpo_rec.recommendation_type
            
        elif strategy == RecommendationStrategy.SECTOR_ROTATION:
            # NO SECTOR CHANGE - this strategy now means different approaches within the same sector
            # Keep the user's selected sector, just vary the approach
            pass  # No sector change
            
        elif strategy == RecommendationStrategy.MOMENTUM_BASED:
            # Follow sentiment within the user's sector, don't change sector
            # Just adjust recommendation type based on sentiment
            sector_sentiment = market_state.sector_sentiments.get(grpo_rec.sector, 0.0)
            grpo_rec.recommendation_type = "invest" if sector_sentiment > 0.2 else "monitor"
            
        elif strategy == RecommendationStrategy.CONTRARIAN_OPPORTUNITY:
            # Go against sentiment within the user's sector, don't change sector
            # Just adjust recommendation type based on contrarian view
            sector_sentiment = market_state.sector_sentiments.get(grpo_rec.sector, 0.0)
            grpo_rec.recommendation_type = "invest" if sector_sentiment < -0.3 else "monitor"
        
        return grpo_rec, grpo_p_rec

    def _create_enhanced_recommendation(self, blended, strategy, user, market_state, index):
        """Create a comprehensive enhanced recommendation with evidence"""
        
        # Generate company information
        companies = self._generate_company_recommendations(blended.sector, strategy, user)
        
        # Generate supporting evidence
        articles = self._generate_supporting_evidence(blended.sector, blended.recommendation_type)
        
        # Generate market analysis
        market_analysis = self._generate_market_analysis(blended.sector, market_state)
        
        # Generate policy impact
        policy_impact = self._generate_policy_impact(blended.sector)
        
        # Generate comprehensive reasoning
        reasoning = self._generate_comprehensive_reasoning(
            blended, strategy, companies, articles, market_analysis, policy_impact
        )
        
        return EnhancedRecommendation(
            sector=blended.sector,
            action=blended.recommendation_type,
            confidence=blended.confidence,
            risk_level=blended.risk_level,
            strategy_type=strategy,
            target_companies=companies,
            investment_amount=self._suggest_investment_amount(user, blended),
            time_horizon=self._suggest_time_horizon(strategy, blended),
            entry_strategy=self._suggest_entry_strategy(strategy, blended),
            unique_angle=self._generate_unique_angle(strategy, blended, index),
            supporting_articles=articles,
            market_analysis=market_analysis,
            policy_impact=policy_impact,
            risk_factors=self._identify_risk_factors(blended, market_state),
            opportunity_factors=self._identify_opportunity_factors(blended, market_state),
            grpo_weight=blended.grpo_weight,
            grpo_p_weight=blended.grpo_p_weight,
            blending_strategy=blended.blending_strategy,
            comprehensive_reasoning=reasoning["comprehensive"],
            market_context=reasoning["context"],
            investment_thesis=reasoning["thesis"],
            what_makes_this_different=reasoning["differentiation"],
            competitive_advantage=reasoning["advantage"],
            market_timing=reasoning["timing"]
        )

    def _generate_company_recommendations(self, sector, strategy, user):
        """Generate dynamic company recommendations based on real news and market data ONLY"""
        
        try:
            # Get real companies from news analysis - NO FALLBACK
            companies = self._extract_companies_from_news(sector, user.location)
            
            if not companies:
                logger.warning(f"âš ï¸  No companies extracted from news for {sector} in {user.location}")
                logger.warning(f"âš ï¸  This indicates the dynamic extraction pipeline needs debugging")
                # NO FALLBACK - return empty list to force dynamic behavior
                return []
            
            # Apply strategy-based filtering while keeping sector/location consistent
            filtered_companies = self._filter_companies_by_strategy(companies, strategy)
            
            logger.info(f"âœ… Successfully extracted {len(filtered_companies)} real companies from news")
            return filtered_companies[:4]  # Return top 4 companies
            
        except Exception as e:
            logger.error(f"Error generating dynamic company recommendations: {e}")
            # NO FALLBACK - return empty list to force dynamic behavior
            return []

    def _get_fallback_companies(self, sector: str, location: str) -> List[CompanyInfo]:
        """NO FALLBACK - This method should never be called in a truly dynamic system"""
        
        logger.error(f"âŒ FALLBACK METHOD CALLED - This indicates dynamic extraction failed!")
        logger.error(f"âŒ Sector: {sector}, Location: {location}")
        logger.error(f"âŒ The system should be extracting real companies from news data")
        
        # Return empty list to force debugging of dynamic pipeline
        return []

    def _get_emergency_fallback_companies(self, sector: str, location: str) -> List[CompanyInfo]:
        """NO EMERGENCY FALLBACK - This method should never be called"""
        
        logger.error(f"âŒ EMERGENCY FALLBACK METHOD CALLED - Dynamic system broken!")
        logger.error(f"âŒ This indicates a critical failure in the news processing pipeline")
        
        # Return empty list to force debugging
        return []

    def _extract_companies_from_news(self, sector: str, location: str) -> List[CompanyInfo]:
        """Extract real companies mentioned in news articles for the sector and location"""
        
        companies = []
        
        try:
            # Fetch recent news for the sector and location
            search_query = f"{sector} {location}"
            news_articles = self._fetch_sector_location_news(search_query, days_back=7)
            
            # FIXED: Proper DataFrame empty check
            if news_articles is None or news_articles.empty:
                logger.warning(f"No news found for {sector} in {location}")
                # NO FALLBACK - return empty list to force dynamic behavior
                return []
            
            # Process each article to extract companies
            for _, article in news_articles.iterrows():
                article_companies = self._extract_companies_from_article(article, sector, location)
                companies.extend(article_companies)
            
            # Remove duplicates and aggregate sentiment
            unique_companies = self._aggregate_company_sentiment(companies)
            
            # Sort by relevance and sentiment
            sorted_companies = sorted(unique_companies, 
                                   key=lambda x: (x.confidence_score, x.relevance_score), 
                                   reverse=True)
            
            logger.info(f"Extracted {len(sorted_companies)} companies from news for {sector} in {location}")
            return sorted_companies
            
        except Exception as e:
            logger.error(f"Error extracting companies from news: {e}")
            # NO FALLBACK - return empty list to force dynamic behavior
            return []

    def _fetch_sector_location_news(self, search_query: str, days_back: int = 7) -> pd.DataFrame:
        """Fetch news articles for specific sector and location with enhanced filtering"""
        
        try:
            sector = search_query.split()[0]
            location = search_query.split()[-1]
            
            logger.info(f"ðŸ” Fetching news for sector: {sector}, location: {location}")
            
            # Use the existing news collector to fetch relevant news
            news_data = self.news_collector.fetch_business_news(
                days_back=days_back, 
                sectors=[sector]
            )
            
            if news_data is None or news_data.empty:
                logger.warning(f"No sector-specific news found for {sector}")
                # Try broader search
                news_data = self.news_collector.fetch_business_news(days_back=days_back)
            
            if news_data is not None and not news_data.empty:
                # CRITICAL FIX: Process news through TextProcessor BEFORE accessing sentiment
                logger.info(f"ðŸ“Š Processing {len(news_data)} raw articles through TextProcessor...")
                processed_news = self.text_processor.process_news_dataframe(news_data)
                
                if processed_news is not None and not processed_news.empty:
                    # Enhanced location filtering with multiple strategies
                    filtered_news = self._enhanced_location_filtering(processed_news, location, sector)
                    
                    if filtered_news.empty:
                        logger.warning(f"ðŸ“ No location-specific news found for {location}, using sector-specific news")
                        # Filter by sector only
                        sector_mask = processed_news['primary_sector'].str.lower() == sector.lower()
                        filtered_news = processed_news[sector_mask]
                        logger.info(f"ðŸ“ Found {len(filtered_news)} sector-specific articles for {sector}")
                    
                    return filtered_news
                else:
                    logger.warning("TextProcessor returned empty/null data")
                    return pd.DataFrame()
            
            return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"Error fetching sector-location news: {e}")
            return pd.DataFrame()

    def _enhanced_location_filtering(self, news_data: pd.DataFrame, location: str, sector: str) -> pd.DataFrame:
        """Enhanced location filtering with multiple strategies"""
        
        if news_data.empty:
            return news_data
        
        try:
            location_keywords = self._get_comprehensive_location_keywords(location)
            logger.info(f"ðŸ” Using location keywords: {location_keywords}")
            
            # Strategy 1: Direct location mentions in title/content
            direct_mask = news_data.apply(
                lambda row: any(keyword.lower() in str(row.get('title', '') + ' ' + str(row.get('content', ''))).lower()
                              for keyword in location_keywords),
                axis=1
            )
            
            # Strategy 2: Location in source name (local news sources)
            source_mask = news_data.apply(
                lambda row: any(keyword.lower() in str(row.get('source_name', '')).lower()
                              for keyword in location_keywords),
                axis=1
            )
            
            # Strategy 3: Sector-specific location indicators
            sector_location_mask = news_data.apply(
                lambda row: self._check_sector_location_relevance(row, sector, location),
                axis=1
            )
            
            # Strategy 4: Partial location matches
            partial_mask = news_data.apply(
                lambda row: any(keyword.split()[0].lower() in str(row.get('title', '') + ' ' + str(row.get('content', ''))).lower()
                              for keyword in location_keywords if ' ' in keyword),
                axis=1
            )
            
            # Combine all strategies
            combined_mask = direct_mask | source_mask | sector_location_mask | partial_mask
            
            filtered_news = news_data[combined_mask]
            
            logger.info(f"ðŸ“ Location filtering results:")
            logger.info(f"   Direct mentions: {direct_mask.sum()}")
            logger.info(f"   Source matches: {source_mask.sum()}")
            logger.info(f"   Sector-location: {sector_location_mask.sum()}")
            logger.info(f"   Partial matches: {partial_mask.sum()}")
            logger.info(f"   Total filtered: {len(filtered_news)}")
            
            return filtered_news
            
        except Exception as e:
            logger.error(f"Error in enhanced location filtering: {e}")
            return pd.DataFrame()

    def _check_sector_location_relevance(self, row: pd.Series, sector: str, location: str) -> bool:
        """Check if article is relevant to sector-location combination"""
        
        try:
            title = str(row.get('title', '')).lower()
            content = str(row.get('content', '')).lower()
            text = title + " " + content
            
            # Sector-location specific patterns
            patterns = {
                "manufacturing": {
                    "bangalore": ["karnataka", "south india", "tech hub", "startup", "it", "software", "electronics", "aerospace"],
                    "mumbai": ["maharashtra", "financial capital", "port", "trade", "industrial", "manufacturing"],
                    "delhi": ["ncr", "north india", "capital", "government", "industrial", "automotive"],
                    "chennai": ["tamil nadu", "automotive", "manufacturing", "industrial", "port"]
                },
                "technology": {
                    "bangalore": ["silicon valley", "tech hub", "startup capital", "it", "software", "digital"],
                    "mumbai": ["financial tech", "fintech", "digital banking", "tech startup"],
                    "delhi": ["tech startup", "digital india", "government tech", "edtech"],
                    "chennai": ["tech hub", "software", "it services", "digital"]
                },
                "finance": {
                    "bangalore": ["fintech", "digital banking", "tech finance", "startup funding"],
                    "mumbai": ["bse", "nse", "financial capital", "banking", "investment"],
                    "delhi": ["government finance", "public sector", "banking", "investment"],
                    "chennai": ["banking", "financial services", "investment"]
                }
            }
            
            sector_patterns = patterns.get(sector.lower(), {})
            location_patterns = sector_patterns.get(location.lower(), [])
            
            # Check if any pattern matches
            for pattern in location_patterns:
                if pattern in text:
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"Error checking sector-location relevance: {e}")
            return False

    def _get_comprehensive_location_keywords(self, location: str) -> List[str]:
        """Get comprehensive keywords for a location with sector-specific variations"""
        
        base_mapping = {
            "mumbai": ["mumbai", "bombay", "maharashtra", "bse", "nse", "financial capital", "port city"],
            "delhi": ["delhi", "ncr", "gurgaon", "noida", "faridabad", "national capital", "north india"],
            "bangalore": ["bangalore", "bengaluru", "karnataka", "silicon valley", "tech hub", "startup capital", "south india"],
            "chennai": ["chennai", "madras", "tamil nadu", "automotive hub", "port city", "south india"],
            "hyderabad": ["hyderabad", "telangana", "pharma city", "cyberabad", "south india"],
            "pune": ["pune", "maharashtra", "oxford of east", "automotive", "western india"],
            "kolkata": ["kolkata", "calcutta", "west bengal", "cultural capital", "east india"]
        }
        
        base_keywords = base_mapping.get(location.lower(), [location.lower()])
        
        # Add common abbreviations and variations
        if location.lower() == "bangalore":
            base_keywords.extend(["bengaluru", "karnataka", "tech", "startup", "it", "south"])
        elif location.lower() == "mumbai":
            base_keywords.extend(["bombay", "maharashtra", "financial", "bse", "nse", "west"])
        elif location.lower() == "delhi":
            base_keywords.extend(["ncr", "gurgaon", "noida", "capital", "north"])
        elif location.lower() == "chennai":
            base_keywords.extend(["madras", "tamil nadu", "automotive", "south"])
        
        # Add regional indicators
        if location.lower() in ["bangalore", "chennai", "hyderabad"]:
            base_keywords.extend(["south india", "southern", "karnataka", "tamil nadu", "telangana"])
        elif location.lower() in ["mumbai", "pune"]:
            base_keywords.extend(["western india", "maharashtra", "west"])
        elif location.lower() in ["delhi", "gurgaon", "noida"]:
            base_keywords.extend(["north india", "ncr", "northern"])
        
        return list(set(base_keywords))  # Remove duplicates

    def _extract_companies_from_article(self, article: pd.Series, sector: str, location: str) -> List[CompanyInfo]:
        """Extract company information from a single news article"""
        
        companies = []
        
        try:
            # Extract text content
            title = str(article.get('title', ''))
            content = str(article.get('content', ''))
            source = str(article.get('source_name', ''))
            
            # Use NER-like extraction to find company names
            company_names = self._extract_company_names(title + " " + content)
            
            # Filter companies by relevance to sector and location
            relevant_companies = self._filter_companies_by_relevance(
                company_names, sector, location, title, content
            )
            
            # Create CompanyInfo objects
            for company_name in relevant_companies:
                company_info = CompanyInfo(
                    name=company_name,
                    sector=sector,
                    location=location,
                    description=self._generate_company_description(company_name, title, content),
                    confidence_score=self._calculate_company_confidence(company_name, article),
                    risk_level=self._assess_company_risk(company_name, article),
                    relevance_score=self._calculate_relevance_score(company_name, sector, location, article)
                )
                companies.append(company_info)
            
            return companies
            
        except Exception as e:
            logger.error(f"Error extracting companies from article: {e}")
            return []

    def _extract_company_names(self, text: str) -> List[str]:
        """Extract company names from text using improved pattern matching for real news"""
        
        companies = []
        
        # More intelligent patterns for real news data
        import re
        
        # Pattern 1: Look for companies with business suffixes (most reliable)
        business_suffix_patterns = [
            r'\b([A-Z][A-Za-z0-9&\-]+(?:\s+[A-Z][A-Za-z0-9&\-]+){0,2})\s+(?:Ltd|Limited|Inc|Corp|Corporation|Group|Technologies|Systems|Solutions|Services|Industries|Enterprises|International|Global|Digital|Tech|Financial|Capital|Investment|Trading|Bank|Insurance|Pharma|Biotech|Energy|Power|Manufacturing|Retail|Healthcare|Real Estate|Construction|Infrastructure|Automotive|Aerospace|Defense|Electronics|Software|Hardware|Telecom|Media|Entertainment)\b',
            # Companies with common business words
            r'\b([A-Z][A-Za-z0-9&\-]+(?:\s+[A-Z][A-Za-z0-9&\-]+){0,2})\s+(?:Company|Co|Enterprises|Partners|Associates|Holdings|Ventures|Capital|Fund|Trust|Foundation)\b'
        ]
        
        # Pattern 2: Look for known major companies
        known_companies = [
            "Apple", "Google", "Microsoft", "Amazon", "Tesla", "Honda", "Toyota", "Samsung", "Sony", "Nike",
            "Coca-Cola", "Pepsi", "McDonald's", "Starbucks", "Walmart", "Target", "Home Depot", "Costco",
            "JPMorgan", "Bank of America", "Wells Fargo", "Goldman Sachs", "Morgan Stanley", "BlackRock",
            "Johnson & Johnson", "Pfizer", "Moderna", "BioNTech", "AstraZeneca", "Novartis", "Roche",
            "ExxonMobil", "Chevron", "BP", "Shell", "Total", "Eni", "ConocoPhillips", "Valero",
            "General Electric", "Siemens", "ABB", "Schneider Electric", "Eaton", "Emerson", "Rockwell"
        ]
        
        # Pattern 3: Look for capitalized multi-word sequences (but be more selective)
        flexible_patterns = [
            r'\b([A-Z][A-Za-z0-9&\-]+(?:\s+[A-Z][A-Za-z0-9&\-]+){1,3})\b'
        ]
        
        # Extract from business suffix patterns first (highest quality)
        for pattern in business_suffix_patterns:
            matches = re.findall(pattern, text)
            companies.extend(matches)
        
        # Extract known companies
        for company in known_companies:
            if company.lower() in text.lower():
                companies.append(company)
        
        # Extract from flexible patterns last (lowest quality)
        for pattern in flexible_patterns:
            matches = re.findall(pattern, text)
            companies.extend(matches)
        
        # Enhanced filtering - remove obviously non-company terms
        obvious_stop_words = {
            "The", "And", "For", "With", "This", "That", "A", "An", "In", "On", "At", "To", "Of",
            "News", "Report", "Article", "Story", "Update", "Analysis", "Commentary", "Says", "According",
            "From", "Does", "Think", "Would", "Much", "Gifts", "Gives", "Wife", "Tuesday", "Monday",
            "Image", "Credit", "Extreme", "Colorado", "Colorados", "Roll", "Uranus", "Davis", "Plaza",
            "These", "Jordan", "Barrel", "White", "Growth", "Global", "Better", "Support", "Save",
            "Water", "Smart", "Nick", "Sean", "Payton", "Denver", "Kerry", "Hisense", "Cinema-sized"
        }
        
        # Location-specific obvious stops
        location_stops = {"Mumbai", "Delhi", "Bangalore", "Chennai", "Hyderabad", "Pune", "Kolkata", "Bombay", "Madras", "India", "Indian"}
        
        filtered_companies = []
        for company in companies:
            words = company.split()
            # More strict validation for better quality
            if len(company) >= 2 and company[0].isupper():
                # Check if first word is not an obvious stop word
                if words[0] not in obvious_stop_words and words[0] not in location_stops:
                    # Additional validation: company should look meaningful
                    if not company.isupper() and not company.islower():
                        # Check if it contains at least one meaningful word
                        meaningful_words = [w for w in words if len(w) > 2 and w not in obvious_stop_words]
                        if len(meaningful_words) >= 1:
                            filtered_companies.append(company)
        
        # Remove duplicates and sort by quality (shorter, cleaner names first)
        unique_companies = list(set(filtered_companies))
        
        # Prioritize companies with business suffixes
        def company_quality(company):
            quality = 0
            if any(suffix in company for suffix in ["Ltd", "Inc", "Corp", "Group", "Technologies"]):
                quality += 10
            if company in known_companies:
                quality += 20
            if len(company.split()) <= 2:
                quality += 5
            return quality
        
        unique_companies.sort(key=company_quality, reverse=True)
        
        logger.info(f"ðŸ” Extracted {len(unique_companies)} potential company names: {unique_companies[:5]}")
        return unique_companies[:5]  # Return top 5 highest quality companies

    def _looks_like_company_name(self, name: str) -> bool:
        """More flexible check if a name looks like a company name"""
        
        # Company name indicators
        company_indicators = [
            "Bank", "Corp", "Inc", "Ltd", "Limited", "Group", "Solutions", "Technologies",
            "Systems", "Services", "Industries", "Enterprises", "International", "Global",
            "Digital", "Tech", "Financial", "Capital", "Investment", "Trading", "Insurance",
            "Pharma", "Biotech", "Energy", "Power", "Manufacturing", "Retail", "Healthcare",
            "Real Estate", "Construction", "Infrastructure", "Automotive", "Telecom", "Media",
            "Software", "Hardware", "Electronics", "Aerospace", "Defense", "Telecom", "Mobile"
        ]
        
        name_lower = name.lower()
        
        # Check if name contains company indicators
        for indicator in company_indicators:
            if indicator.lower() in name_lower:
                return True
        
        # More flexible structure validation
        words = name.split()
        if len(words) >= 1 and len(words) <= 5:  # 1-5 words is reasonable for company names
            # First word should start with capital letter
            if words[0][0].isupper():
                # Check if it's not just common words
                common_words = {"The", "New", "First", "Second", "Third", "One", "Two", "Three", "India", "Indian"}
                if words[0] not in common_words:
                    return True
        
        return False

    def _filter_companies_by_relevance(self, company_names: List[str], sector: str, 
                                     location: str, title: str, content: str) -> List[str]:
        """Filter companies by relevance to sector and location"""
        
        relevant_companies = []
        
        for company in company_names:
            relevance_score = 0
            
            # Check sector relevance
            if self._is_company_relevant_to_sector(company, sector, title, content):
                relevance_score += 2
            
            # Check location relevance
            if self._is_company_relevant_to_location(company, location, title, content):
                relevance_score += 2
            
            # Check if mentioned in title (higher relevance)
            if company.lower() in title.lower():
                relevance_score += 1
            
            # Only include companies with sufficient relevance
            if relevance_score >= 2:
                relevant_companies.append(company)
        
        return relevant_companies

    def _is_company_relevant_to_sector(self, company: str, sector: str, title: str, content: str) -> bool:
        """Check if company is relevant to the specified sector"""
        
        # Sector-specific keywords
        sector_keywords = {
            "finance": ["bank", "financial", "fintech", "payment", "insurance", "investment", "credit"],
            "technology": ["tech", "software", "digital", "ai", "cloud", "cybersecurity", "startup"],
            "energy": ["power", "energy", "renewable", "solar", "wind", "electric", "oil", "gas"],
            "healthcare": ["health", "medical", "pharma", "biotech", "hospital", "clinic", "diagnostic"],
            "retail": ["retail", "ecommerce", "shopping", "consumer", "marketplace", "store"],
            "manufacturing": ["manufacturing", "industrial", "factory", "production", "machinery"],
            "real_estate": ["real estate", "property", "construction", "housing", "development"]
        }
        
        keywords = sector_keywords.get(sector.lower(), [])
        text_lower = (title + " " + content).lower()
        
        # Check if any sector keywords appear near the company name
        for keyword in keywords:
            if keyword in text_lower:
                return True
        
        return False

    def _is_company_relevant_to_location(self, company: str, location: str, title: str, content: str) -> bool:
        """Check if company is relevant to the specified location"""
        
        text_lower = (title + " " + content).lower()
        location_lower = location.lower()
        
        # Check if location is mentioned in the text
        if location_lower in text_lower:
            return True
        
        # Check for location-specific keywords
        location_keywords = {
            "mumbai": ["mumbai", "bombay", "maharashtra"],
            "delhi": ["delhi", "ncr", "gurgaon", "noida", "faridabad"],
            "bangalore": ["bangalore", "bengaluru", "karnataka"],
            "chennai": ["chennai", "madras", "tamil nadu"],
            "hyderabad": ["hyderabad", "telangana"],
            "pune": ["pune", "maharashtra"],
            "kolkata": ["kolkata", "calcutta", "west bengal"]
        }
        
        keywords = location_keywords.get(location_lower, [])
        for keyword in keywords:
            if keyword in text_lower:
                return True
        
        return False

    def _generate_company_description(self, company_name: str, title: str, content: str) -> str:
        """Generate concise, readable company description from news content"""
        
        # Try to extract a meaningful description from the content
        text = title + " " + content
        
        # Clean up HTML entities and extra whitespace
        text = text.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
        text = ' '.join(text.split())
        
        # Look for sentences that mention the company
        sentences = text.split('.')
        company_sentences = []
        
        for sentence in sentences:
            if company_name.lower() in sentence.lower():
                # Clean up the sentence
                clean_sentence = sentence.strip()
                company_sentences.append(clean_sentence)
        
        if company_sentences:
            # Use the first relevant sentence, but make it concise
            description = company_sentences[0]
            
            # Find a good breaking point for readability
            if len(description) > 80:
                # Try to break at a natural point
                words = description.split()
                for i in range(len(words)):
                    if len(' '.join(words[:i+1])) > 80:
                        # Look for a better breaking point (end of phrase)
                        for j in range(i, max(0, i-5), -1):
                            if words[j].endswith(('.', '!', '?', ':', ';')):
                                description = ' '.join(words[:j+1])
                                break
                        else:
                            description = ' '.join(words[:i]) + "..."
                        break
            else:
                description = description[:80]
            
            return description
        else:
            # Generate a generic but meaningful description based on context
            if "energy" in text.lower() or "power" in text.lower():
                return f"{company_name} - Energy company mentioned in recent business news"
            elif "manufacturing" in text.lower() or "industrial" in text.lower():
                return f"{company_name} - Manufacturing company mentioned in recent business news"
            elif "technology" in text.lower() or "digital" in text.lower():
                return f"{company_name} - Technology company mentioned in recent business news"
            elif "finance" in text.lower() or "banking" in text.lower():
                return f"{company_name} - Financial company mentioned in recent business news"
            else:
                return f"{company_name} - Company mentioned in recent business news"

    def _calculate_company_confidence(self, company_name: str, article: pd.Series) -> float:
        """Calculate realistic company confidence based on article sentiment and source reliability"""
        
        try:
            # Get article sentiment
            sentiment = float(article.get('business_sentiment', 0.0))
            
            # Normalize sentiment to 0-1 scale
            normalized_sentiment = (sentiment + 1.0) / 2.0
            
            # Source reliability factor
            source = str(article.get('source_name', '')).lower()
            reliable_sources = ['economic times', 'business standard', 'times of india', 'hindustan times', 'reuters', 'bloomberg', 'cnbc', 'forbes']
            source_factor = 1.2 if source in reliable_sources else 1.0
            
            # Company name quality factor
            name_quality = 1.0
            if len(company_name.split()) >= 3:  # Long names might be less reliable
                name_quality = 0.8
            elif len(company_name.split()) == 1:  # Single word names might be generic
                name_quality = 0.7
            
            # Calculate base confidence
            base_confidence = normalized_sentiment * source_factor * name_quality
            
            # Add some randomness to make it realistic (not all 95%)
            import random
            random.seed(hash(company_name) % 1000)  # Deterministic randomness
            variation = random.uniform(-0.15, 0.15)
            
            confidence = base_confidence + variation
            
            # Ensure confidence is within realistic bounds
            confidence = max(0.1, min(0.85, confidence))
            
            return round(confidence, 2)  # Round to 2 decimal places
            
        except Exception as e:
            logger.error(f"Error calculating company confidence: {e}")
            return 0.5  # Default confidence

    def _assess_company_risk(self, company_name: str, article: pd.Series) -> str:
        """Assess company risk level based on article content and sentiment"""
        
        try:
            # Get article sentiment
            sentiment = float(article.get('business_sentiment', 0.0))
            
            # Risk keywords that indicate higher risk
            high_risk_keywords = [
                "risk", "volatile", "uncertainty", "challenge", "decline", "loss", "debt",
                "regulatory", "investigation", "lawsuit", "bankruptcy", "crisis"
            ]
            
            text = str(article.get('title', '')) + " " + str(article.get('content', ''))
            text_lower = text.lower()
            
            # Count risk keywords
            risk_count = sum(1 for keyword in high_risk_keywords if keyword in text_lower)
            
            # Determine risk level based on sentiment and risk keywords
            if sentiment < -0.3 or risk_count >= 2:
                return "high"
            elif sentiment < 0.1 or risk_count >= 1:
                return "moderate"
            else:
                return "low"
            
        except Exception as e:
            logger.error(f"Error assessing company risk: {e}")
            return "moderate"  # Default risk level

    def _calculate_relevance_score(self, company_name: str, sector: str, location: str, article: pd.Series) -> float:
        """Calculate relevance score for company based on multiple factors"""
        
        relevance_score = 0.0
        
        try:
            # Title mention (highest relevance)
            title = str(article.get('title', '')).lower()
            if company_name.lower() in title:
                relevance_score += 0.4
            
            # Sector relevance
            if self._is_company_relevant_to_sector(company_name, sector, str(article.get('title', '')), str(article.get('content', ''))):
                relevance_score += 0.3
            
            # Location relevance
            if self._is_company_relevant_to_location(company_name, location, str(article.get('title', '')), str(article.get('content', ''))):
                relevance_score += 0.3
            
            # Recency factor (more recent = higher relevance)
            try:
                published_date = pd.to_datetime(article.get('published_at', ''))
                days_old = (pd.Timestamp.now() - published_date).days
                if days_old <= 1:
                    relevance_score += 0.2
                elif days_old <= 3:
                    relevance_score += 0.1
            except:
                pass
            
            return min(1.0, relevance_score)
            
        except Exception as e:
            logger.error(f"Error calculating relevance score: {e}")
            return 0.5

    def _aggregate_company_sentiment(self, companies: List[CompanyInfo]) -> List[CompanyInfo]:
        """Aggregate sentiment for companies mentioned in multiple articles"""
        
        company_dict = {}
        
        for company in companies:
            if company.name not in company_dict:
                company_dict[company.name] = company
            else:
                # Aggregate sentiment and improve confidence
                existing = company_dict[company.name]
                existing.confidence_score = (existing.confidence_score + company.confidence_score) / 2
                existing.relevance_score = max(existing.relevance_score, company.relevance_score)
        
        return list(company_dict.values())

    def _filter_companies_by_strategy(self, companies: List[CompanyInfo], strategy: RecommendationStrategy) -> List[CompanyInfo]:
        """Filter companies based on investment strategy"""
        
        if not companies:
            return companies
        
        if strategy == RecommendationStrategy.CONSERVATIVE_LONG_TERM:
            # Prefer lower risk, established companies
            return sorted(companies, key=lambda x: (x.risk_level != "low", -x.confidence_score))
        elif strategy == RecommendationStrategy.AGGRESSIVE_SHORT_TERM:
            # Prefer higher risk, growth companies
            return sorted(companies, key=lambda x: (x.risk_level != "high", -x.confidence_score))
        else:
            # Balanced approach
            return sorted(companies, key=lambda x: (-x.confidence_score, -x.relevance_score))

    def _generate_supporting_evidence(self, sector, action_type):
        """Generate supporting news evidence for the recommendation - NO FALLBACK"""
        
        try:
            # Get real news articles for the sector
            news_articles = self._fetch_sector_news_for_evidence(sector, action_type)
            
            # FIXED: Proper DataFrame empty check
            if news_articles is None or news_articles.empty:
                # NO FALLBACK - return empty list to force dynamic behavior
                logger.warning(f"âš ï¸  No real news found for {sector}/{action_type} - evidence generation failed")
                return []
            
            # Convert news articles to ArticleSummary objects
            articles = []
            for _, article in news_articles.head(3).iterrows():  # Top 3 articles
                article_summary = self._create_article_summary(article, sector, action_type)
                if article_summary:
                    articles.append(article_summary)
            
            if not articles:
                logger.warning(f"âš ï¸  Failed to create article summaries for {sector}/{action_type}")
                return []
            
            logger.info(f"âœ… Generated {len(articles)} real evidence articles for {sector}/{action_type}")
            return articles
            
        except Exception as e:
            logger.error(f"Error generating supporting evidence: {e}")
            # NO FALLBACK - return empty list to force dynamic behavior
            return []

    def _generate_fallback_evidence(self, sector: str, action_type: str) -> List[ArticleSummary]:
        """NO FALLBACK EVIDENCE - This method should never be called"""
        
        logger.error(f"âŒ FALLBACK EVIDENCE METHOD CALLED - Dynamic evidence generation failed!")
        logger.error(f"âŒ Sector: {sector}, Action: {action_type}")
        logger.error(f"âŒ The system should be generating evidence from real news data")
        
        # Return empty list to force debugging of dynamic pipeline
        return []

    def _fetch_sector_news_for_evidence(self, sector: str, action_type: str) -> pd.DataFrame:
        """Fetch real news articles for supporting evidence"""
        
        try:
            # Fetch recent news for the sector
            news_data = self.news_collector.fetch_business_news(days_back=7, sectors=[sector])
            
            if news_data is None or news_data.empty:
                return pd.DataFrame()
            
            # CRITICAL FIX: Process news through TextProcessor BEFORE accessing sentiment
            logger.info(f"ðŸ“Š Processing {len(news_data)} news articles for evidence...")
            processed_news = self.text_processor.process_news_dataframe(news_data)
            
            if processed_news is None or processed_news.empty:
                logger.warning("TextProcessor returned empty data for evidence")
                return pd.DataFrame()
            
            # Now we can safely access business_sentiment column
            # Filter articles based on action type
            if action_type == "invest":
                # Look for positive sentiment articles
                positive_mask = processed_news['business_sentiment'] > 0.1
                filtered_news = processed_news[positive_mask]
            elif action_type == "monitor":
                # Look for neutral sentiment articles
                neutral_mask = (processed_news['business_sentiment'] >= -0.1) & (processed_news['business_sentiment'] <= 0.1)
                filtered_news = processed_news[neutral_mask]
            else:  # avoid
                # Look for negative sentiment articles
                negative_mask = processed_news['business_sentiment'] < -0.1
                filtered_news = processed_news[negative_mask]
            
            # Sort by relevance and recency
            if not filtered_news.empty:
                filtered_news = filtered_news.sort_values(['business_sentiment', 'published_at'], ascending=[False, False])
                logger.info(f"ðŸ“ˆ Found {len(filtered_news)} sentiment-filtered articles for {action_type}")
            
            return filtered_news
            
        except Exception as e:
            logger.error(f"Error fetching sector news for evidence: {e}")
            return pd.DataFrame()

    def _create_article_summary(self, article: pd.Series, sector: str, action_type: str) -> Optional[ArticleSummary]:
        """Create ArticleSummary from news article data with better error handling"""
        
        try:
            # Extract key information with better error handling
            title = str(article.get('title', ''))
            source = str(article.get('source_name', ''))
            published_date = str(article.get('published_at', ''))
            
            # Handle missing business_sentiment gracefully
            try:
                sentiment = float(article.get('business_sentiment', 0.0))
            except (ValueError, TypeError):
                sentiment = 0.0
            
            # Clean up title and content
            title = title.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
            title = ' '.join(title.split())
            
            # Validate required fields
            if not title or not source or not published_date:
                logger.warning(f"Missing required fields: title={bool(title)}, source={bool(source)}, date={bool(published_date)}")
                return None
            
            # Extract key points from the article
            key_points = self._extract_key_points_from_article(article, sector)
            
            # Calculate relevance score
            relevance_score = self._calculate_article_relevance(article, sector, action_type)
            
            # Only include articles with sufficient relevance
            if relevance_score < 0.2:  # Lowered threshold for better coverage
                logger.debug(f"Article relevance too low: {relevance_score}")
                return None
            
            # Create the summary
            summary = ArticleSummary(
                title=title[:100] + "..." if len(title) > 100 else title,
                source=source,
                published_date=published_date,
                sentiment=sentiment,
                key_points=key_points,
                relevance_score=relevance_score
            )
            
            logger.debug(f"âœ… Created article summary: {title[:50]}...")
            return summary
            
        except Exception as e:
            logger.error(f"Error creating article summary: {e}")
            return None

    def _extract_key_points_from_article(self, article: pd.Series, sector: str) -> List[str]:
        """Extract key points from article content"""
        
        try:
            title = str(article.get('title', ''))
            content = str(article.get('content', ''))
            
            # Combine title and content
            full_text = title + " " + content
            
            # Clean up HTML entities
            full_text = full_text.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
            
            # Extract key points using simple heuristics
            key_points = []
            
            # Look for sentences with sector keywords
            sector_keywords = self._get_sector_keywords(sector)
            sentences = full_text.split('.')
            
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) < 20:  # Skip very short sentences
                    continue
                    
                # Check if sentence contains sector keywords
                if any(keyword in sentence.lower() for keyword in sector_keywords):
                    # Clean up the sentence
                    clean_sentence = ' '.join(sentence.split())
                    if len(clean_sentence) > 50:  # Skip very long sentences
                        clean_sentence = clean_sentence[:80] + "..."
                    key_points.append(clean_sentence)
                    
                    # Limit to 3 key points
                    if len(key_points) >= 3:
                        break
            
            # If no sector-specific points found, use general points from title
            if not key_points:
                # Extract key information from title
                title_words = title.split()
                if len(title_words) >= 5:
                    # Take first 5-8 words as key point
                    key_point = ' '.join(title_words[:min(8, len(title_words))])
                    if len(key_point) > 80:
                        key_point = key_point[:80] + "..."
                    key_points.append(key_point)
                else:
                    key_points.append(title[:80] + "..." if len(title) > 80 else title)
            
            # Ensure we have at least one key point
            if not key_points:
                key_points = [f"{sector.title()} sector development and market trends"]
            
            return key_points[:3]  # Return max 3 key points
            
        except Exception as e:
            logger.error(f"Error extracting key points: {e}")
            return [f"{sector.title()} sector analysis and business insights"]

    def _calculate_article_relevance(self, article: pd.Series, sector: str, action_type: str) -> float:
        """Calculate how relevant an article is to the recommendation"""
        
        relevance_score = 0.0
        
        try:
            title = str(article.get('title', '')).lower()
            content = str(article.get('content', '')).lower()
            sentiment = float(article.get('business_sentiment', 0.0))
            
            # Title relevance (higher weight)
            if sector.lower() in title:
                relevance_score += 0.4
            
            # Content relevance
            if sector.lower() in content:
                relevance_score += 0.3
            
            # Sentiment alignment with action type
            if action_type == "invest" and sentiment > 0.2:
                relevance_score += 0.2
            elif action_type == "monitor" and abs(sentiment) <= 0.2:
                relevance_score += 0.2
            elif action_type == "avoid" and sentiment < -0.2:
                relevance_score += 0.2
            
            # Source reliability
            source = str(article.get('source_name', '')).lower()
            reliable_sources = ['economic times', 'business standard', 'times of india', 'hindustan times', 'reuters', 'bloomberg', 'cnbc', 'forbes', 'yahoo finance', 'marketwatch']
            if source in reliable_sources:
                relevance_score += 0.1
            
            # Recency factor
            try:
                published_date = pd.to_datetime(article.get('published_at', ''))
                days_old = (pd.Timestamp.now() - published_date).days
                if days_old <= 1:
                    relevance_score += 0.1
                elif days_old <= 3:
                    relevance_score += 0.05
            except:
                pass
            
            return min(1.0, relevance_score)
            
        except Exception as e:
            logger.error(f"Error calculating article relevance: {e}")
            return 0.5

    def _generate_market_analysis(self, sector, market_state):
        """Generate comprehensive market analysis based on real market data"""
        
        try:
            # Get real market sentiment for the sector
            sector_sentiment = market_state.sector_sentiments.get(sector, 0.0)
            
            # Analyze market trends based on sentiment
            market_trend = self._analyze_market_trend(sector_sentiment)
            
            # Get volatility level from market state
            volatility_level = self._classify_volatility(market_state.volatility)
            
            # Extract key drivers from trending topics
            key_drivers = self._extract_key_drivers_from_trends(sector, market_state.trending_topics)
            
            # Identify risk factors based on market conditions
            risk_factors = self._identify_risk_factors_from_market(sector, market_state)
            
            # Identify opportunity factors
            opportunity_factors = self._identify_opportunity_factors_from_market(sector, market_state)
            
            return MarketAnalysis(
                sector_sentiment=sector_sentiment,
                market_trend=market_trend,
                volatility_level=volatility_level,
                key_drivers=key_drivers,
                risk_factors=risk_factors,
                opportunity_factors=opportunity_factors
            )
            
        except Exception as e:
            logger.error(f"Error generating market analysis: {e}")
            return self._generate_fallback_market_analysis(sector)

    def _analyze_market_trend(self, sentiment: float) -> str:
        """Analyze market trend based on sentiment score"""
        
        if sentiment > 0.3:
            return "bullish"
        elif sentiment < -0.3:
            return "bearish"
        else:
            return "neutral"

    def _classify_volatility(self, volatility: float) -> str:
        """Classify volatility level"""
        
        if volatility > 0.6:
            return "high"
        elif volatility > 0.3:
            return "moderate"
        else:
            return "low"

    def _extract_key_drivers_from_trends(self, sector: str, trending_topics: Dict[str, int]) -> List[str]:
        """Extract key drivers from trending topics"""
        
        drivers = []
        
        # Get sector-specific trending topics
        sector_topics = []
        for topic, count in trending_topics.items():
            if self._is_topic_relevant_to_sector(topic, sector):
                sector_topics.append((topic, count))
        
        # Sort by relevance and take top 3
        sector_topics.sort(key=lambda x: x[1], reverse=True)
        
        for topic, count in sector_topics[:3]:
            if count >= 3:  # Only include topics with sufficient mentions
                drivers.append(f"{topic.title()} momentum (mentioned {count} times)")
        
        # Add general market drivers if not enough sector-specific ones
        if len(drivers) < 3:
            drivers.extend([
                "Market sentiment analysis",
                "Industry developments",
                "Economic indicators"
            ])
        
        return drivers[:3]

    def _is_topic_relevant_to_sector(self, topic: str, sector: str) -> bool:
        """Check if a trending topic is relevant to the sector"""
        
        topic_lower = topic.lower()
        sector_lower = sector.lower()
        
        # Sector-specific topic mappings
        sector_topics = {
            "finance": ["fintech", "banking", "investment", "crypto", "insurance", "credit"],
            "technology": ["ai", "cloud", "cybersecurity", "startup", "software", "digital"],
            "energy": ["renewable", "solar", "wind", "electric", "oil", "gas", "power"],
            "healthcare": ["biotech", "pharma", "medical", "health", "diagnostic", "treatment"],
            "retail": ["ecommerce", "shopping", "consumer", "retail", "marketplace"],
            "manufacturing": ["manufacturing", "industrial", "automation", "production"],
            "real_estate": ["property", "construction", "housing", "real estate", "development"]
        }
        
        relevant_topics = sector_topics.get(sector_lower, [])
        return any(relevant_topic in topic_lower for relevant_topic in relevant_topics)

    def _identify_risk_factors_from_market(self, sector: str, market_state: MarketState) -> List[str]:
        """Identify risk factors based on market conditions"""
        
        risk_factors = []
        
        # Market volatility risk
        if market_state.volatility > 0.6:
            risk_factors.append("High market volatility")
        elif market_state.volatility > 0.3:
            risk_factors.append("Moderate market volatility")
        
        # Sector-specific risks
        sector_risks = {
            "finance": ["Regulatory changes", "Interest rate fluctuations", "Credit risk"],
            "technology": ["Technology disruption", "Cybersecurity threats", "Rapid innovation cycles"],
            "energy": ["Policy changes", "Commodity price volatility", "Environmental regulations"],
            "healthcare": ["Regulatory approvals", "Patent expirations", "Clinical trial risks"],
            "retail": ["Consumer spending changes", "E-commerce disruption", "Supply chain issues"],
            "manufacturing": ["Supply chain disruptions", "Raw material costs", "Labor market changes"],
            "real_estate": ["Interest rate changes", "Property market cycles", "Regulatory changes"]
        }
        
        sector_specific_risks = sector_risks.get(sector.lower(), [])
        risk_factors.extend(sector_specific_risks[:2])  # Add 2 sector-specific risks
        
        # General market risks
        if market_state.overall_sentiment < -0.2:
            risk_factors.append("Overall market pessimism")
        
        # Ensure we have at least 3 risk factors
        while len(risk_factors) < 3:
            risk_factors.append("Economic uncertainty")
        
        return risk_factors[:4]  # Return max 4 risk factors

    def _identify_opportunity_factors_from_market(self, sector: str, market_state: MarketState) -> List[str]:
        """Identify opportunity factors based on market conditions"""
        
        opportunity_factors = []
        
        # Positive sentiment opportunities
        if market_state.sector_sentiments.get(sector, 0.0) > 0.2:
            opportunity_factors.append(f"Strong {sector} sector sentiment")
        
        # Sector-specific opportunities
        sector_opportunities = {
            "finance": ["Digital transformation", "Fintech innovation", "Financial inclusion"],
            "technology": ["AI/ML adoption", "Cloud migration", "Digital transformation"],
            "energy": ["Renewable energy growth", "Energy efficiency", "Green technology"],
            "healthcare": ["Telemedicine growth", "Biotech innovation", "Healthcare digitization"],
            "retail": ["E-commerce growth", "Omnichannel retail", "Digital payments"],
            "manufacturing": ["Industry 4.0", "Automation", "Supply chain optimization"],
            "real_estate": ["Affordable housing", "Smart cities", "Infrastructure development"]
        }
        
        sector_specific_opportunities = sector_opportunities.get(sector.lower(), [])
        opportunity_factors.extend(sector_specific_opportunities[:2])
        
        # Market-wide opportunities
        if market_state.overall_sentiment > 0.2:
            opportunity_factors.append("Positive overall market sentiment")
        
        # Ensure we have at least 3 opportunity factors
        while len(opportunity_factors) < 3:
            opportunity_factors.append(f"{sector.title()} sector growth potential")
        
        return opportunity_factors[:4]  # Return max 4 opportunity factors

    def _generate_fallback_market_analysis(self, sector: str) -> MarketAnalysis:
        """Generate fallback market analysis when real data is not available"""
        
        return MarketAnalysis(
            sector_sentiment=0.0,
            market_trend="neutral",
            volatility_level="moderate",
            key_drivers=["Market analysis", "Industry trends", "Economic indicators"],
            risk_factors=["Market volatility", "Economic uncertainty", "Regulatory changes"],
            opportunity_factors=["Sector growth potential", "Market opportunities", "Innovation potential"]
        )

    def _generate_policy_impact(self, sector):
        """Generate government policy impact analysis"""
        
        if sector == "finance":
            return PolicyImpact(
                policy_type="Fintech Innovation",
                description="RBI's new fintech innovation hub and regulatory sandbox",
                impact_level="high",
                timeline="6-12 months",
                beneficiaries=["Digital banks", "Payment platforms", "Fintech startups"]
            )
        elif sector == "energy":
            return PolicyImpact(
                policy_type="Renewable Energy",
                description="Government's â‚¹50,000 crore solar startup fund and incentives",
                impact_level="very high",
                timeline="3-6 months",
                beneficiaries=["Solar companies", "Renewable startups", "Energy infrastructure"]
            )
        elif sector == "technology":
            return PolicyImpact(
                policy_type="Digital India",
                description="PLI scheme for IT hardware and semiconductor manufacturing",
                impact_level="high",
                timeline="12-18 months",
                beneficiaries=["Hardware manufacturers", "Semiconductor companies", "IT services"]
            )
        else:
            return PolicyImpact(
                policy_type="General Business",
                description="Make in India and startup support policies",
                impact_level="moderate",
                timeline="12-18 months",
                beneficiaries=["Manufacturing", "Technology", "Services"]
            )

    def _generate_comprehensive_reasoning(self, blended, strategy, companies, articles, market_analysis, policy_impact):
        """Generate comprehensive reasoning for the recommendation"""
        
        sector = blended.sector
        action = blended.recommendation_type
        
        # Build comprehensive reasoning
        comprehensive = f"""
        Based on comprehensive analysis of the {sector} sector, we recommend {action} due to:
        
        1. Market Conditions: {market_analysis.market_trend} sentiment with {market_analysis.volatility_level} volatility
        2. Policy Support: {policy_impact.description} with {policy_impact.impact_level} impact
        3. Company Strength: {len(companies)} strong companies identified with confidence scores {[c.confidence_score for c in companies]}
        4. News Evidence: {len(articles)} supporting articles with positive sentiment
        5. Strategy Alignment: {strategy.value} approach optimized for current market conditions
        """.strip()
        
        context = f"""
        The {sector} sector is currently experiencing {market_analysis.market_trend} conditions 
        with key drivers including {', '.join(market_analysis.key_drivers[:2])}. 
        Government policies are supportive with {policy_impact.description}.
        """.strip()
        
        thesis = f"""
        Our investment thesis is based on {action} in {sector} because:
        - Market sentiment is {market_analysis.market_trend}
        - Policy environment is favorable
        - Strong companies available for investment
        - Risk-reward ratio is attractive
        """.strip()
        
        differentiation = f"""
        This recommendation differs from others because it uses a {strategy.value} strategy,
        focuses on {sector} sector, and considers {len(articles)} pieces of supporting evidence.
        """.strip()
        
        advantage = f"""
        Competitive advantages include early mover advantage in {sector},
        government policy support, and strong market fundamentals.
        """.strip()
        
        timing = f"""
        Market timing is favorable due to {market_analysis.market_trend} sentiment,
        policy announcements, and current market conditions.
        """.strip()
        
        return {
            "comprehensive": comprehensive,
            "context": context,
            "thesis": thesis,
            "differentiation": differentiation,
            "advantage": advantage,
            "timing": timing
        }

    def _suggest_investment_amount(self, user, blended):
        """Suggest investment amount based on user profile"""
        
        if user.capital_range == "low":
            return "â‚¹10,000 - â‚¹50,000"
        elif user.capital_range == "medium":
            return "â‚¹50,000 - â‚¹2,00,000"
        else:  # high
            return "â‚¹2,00,000 - â‚¹10,00,000"

    def _suggest_time_horizon(self, strategy, blended):
        """Suggest time horizon based on strategy"""
        
        if strategy == RecommendationStrategy.CONSERVATIVE_LONG_TERM:
            return "3-5 years"
        elif strategy == RecommendationStrategy.AGGRESSIVE_SHORT_TERM:
            return "6-12 months"
        else:
            return "1-3 years"

    def _suggest_entry_strategy(self, strategy, blended):
        """Suggest entry strategy based on strategy"""
        
        if strategy == RecommendationStrategy.CONSERVATIVE_LONG_TERM:
            return "Systematic Investment Plan (SIP)"
        elif strategy == RecommendationStrategy.AGGRESSIVE_SHORT_TERM:
            return "Lump sum investment"
        else:
            return "Phased investment over 3-6 months"

    def _generate_unique_angle(self, strategy, blended, index):
        """Generate unique angle for each recommendation"""
        
        angles = [
            "Early stage opportunity in emerging market",
            "Value play in established sector",
            "Growth potential in innovative segment",
            "Contrarian view against market sentiment",
            "Policy-driven opportunity with government support"
        ]
        
        return angles[index % len(angles)]

    def _identify_risk_factors(self, blended, market_state):
        """Identify specific risk factors"""
        
        return [
            f"Market volatility in {blended.sector} sector",
            "Regulatory changes",
            "Economic uncertainty",
            "Competition intensity",
            "Technology disruption"
        ]

    def _identify_opportunity_factors(self, blended, market_state):
        """Identify specific opportunity factors"""
        
        return [
            f"Strong growth potential in {blended.sector}",
            "Government policy support",
            "Market expansion opportunities",
            "Innovation potential",
            "Strategic partnerships"
        ]

    def _get_current_market_state(self) -> MarketState:
        """Get current market state from news analysis"""
        
        try:
            # Fetch latest news (use recent window; include union of all active users' sectors for relevance)
            active_user_sectors: List[str] = []
            for u in self.active_users.values():
                active_user_sectors.extend(u.sectors)
            sectors = list(sorted(set(active_user_sectors))) or None
            
            logger.info(f"ðŸ” Fetching news for sectors: {sectors}")
            news_articles = self.news_collector.fetch_business_news(days_back=1, sectors=sectors)
            
            # Handle DataFrame return correctly
            if news_articles is None or getattr(news_articles, "empty", False):
                logger.warning("No news articles fetched, using enhanced fallback market state")
                return self._create_enhanced_fallback_market_state(active_user_sectors)
            
            # Process news articles
            processed_df = self.text_processor.process_news_dataframe(news_articles)
            # Keep processed articles for item-level recommendations
            self.latest_processed_df = processed_df
            
            # Calculate market state
            sector_sentiments = {}
            for sector in processed_df['primary_sector'].unique():
                sector_data = processed_df[processed_df['primary_sector'] == sector]
                avg_sentiment = sector_data['business_sentiment'].mean()
                sector_sentiments[sector] = avg_sentiment
            
            overall_sentiment = processed_df['business_sentiment'].mean()
            volatility = processed_df['business_sentiment'].std()
            
            # Extract trending topics
            all_keywords = []
            for keywords_list in processed_df['top_keywords']:
                all_keywords.extend(keywords_list)
            
            from collections import Counter
            trending_topics = dict(Counter(all_keywords).most_common(10))
            
            market_state = MarketState(
                sector_sentiments=sector_sentiments,
                overall_sentiment=overall_sentiment,
                volatility=volatility,
                trending_topics=trending_topics,
                article_count=len(processed_df),
                timestamp=datetime.now().isoformat()
            )
            
            self.latest_market_state = market_state
            
            logger.info(f"ðŸ“ˆ Updated market state with {len(processed_df)} articles")
            logger.info(f"   Overall sentiment: {overall_sentiment:.2f}")
            logger.info(f"   Volatility: {volatility:.2f}")
            
            return market_state
            
        except Exception as e:
            logger.error(f"Error getting market state: {e}")
            return self._create_enhanced_fallback_market_state(active_user_sectors or ["technology", "finance"])
    
    def _create_enhanced_fallback_market_state(self, user_sectors: List[str]) -> MarketState:
        """Create realistic fallback market state with user sector focus"""
        
        # Generate realistic sector sentiments based on current market conditions
        import random
        random.seed(42)  # For reproducible fallback data
        
        # Base sentiments for different sectors (realistic market conditions)
        base_sentiments = {
            "technology": 0.3,      # Generally positive tech sentiment
            "finance": 0.1,         # Slightly positive finance
            "energy": -0.2,         # Mixed energy sentiment
            "healthcare": 0.4,      # Strong healthcare sentiment
            "retail": -0.1,         # Slightly negative retail
            "manufacturing": 0.0,   # Neutral manufacturing
            "real_estate": -0.3     # Negative real estate sentiment
        }
        
        # Add some randomness but keep it realistic
        sector_sentiments = {}
        for sector in user_sectors:
            if sector in base_sentiments:
                base = base_sentiments[sector]
                # Add realistic variation
                variation = random.uniform(-0.2, 0.2)
                sector_sentiments[sector] = max(-1.0, min(1.0, base + variation))
            else:
                # For unknown sectors, generate reasonable sentiment
                sector_sentiments[sector] = random.uniform(-0.3, 0.3)
        
        # Add some non-user sectors for market completeness
        for sector in ["technology", "finance", "energy"]:
            if sector not in sector_sentiments:
                base = base_sentiments.get(sector, 0.0)
                variation = random.uniform(-0.15, 0.15)
                sector_sentiments[sector] = max(-1.0, min(1.0, base + variation))
        
        # Calculate overall sentiment and volatility
        overall_sentiment = sum(sector_sentiments.values()) / len(sector_sentiments)
        volatility = 0.4 + random.uniform(-0.1, 0.1)  # Realistic volatility
        
        # Generate trending topics based on user sectors
        trending_topics = {}
        for sector in user_sectors:
            if sector == "technology":
                trending_topics.update({"AI": 8, "cloud": 6, "cybersecurity": 5})
            elif sector == "finance":
                trending_topics.update({"fintech": 7, "digital banking": 6, "crypto": 4})
            elif sector == "energy":
                trending_topics.update({"renewable": 8, "solar": 6, "EV": 5})
            elif sector == "healthcare":
                trending_topics.update({"biotech": 7, "telemedicine": 6, "AI diagnostics": 5})
        
        # Add some general market topics
        trending_topics.update({"market": 5, "investment": 4, "startup": 3})
        
        logger.info(f"ðŸ”„ Created enhanced fallback market state for sectors: {user_sectors}")
        logger.info(f"   Sector sentiments: {sector_sentiments}")
        logger.info(f"   Overall sentiment: {overall_sentiment:.2f}")
        logger.info(f"   Volatility: {volatility:.2f}")
        
        return MarketState(
            sector_sentiments=sector_sentiments,
            overall_sentiment=overall_sentiment,
            volatility=volatility,
            trending_topics=trending_topics,
            article_count=0,  # Indicates fallback data
            timestamp=datetime.now().isoformat()
        )
    
    def _create_arbitration_context(self, 
                                  user: SystemUser, 
                                  market_state: MarketState) -> ArbitrationContext:
        """Create arbitration context for blending recommendations"""
        
        grpo_p_agent = self.grpo_p_agents[user.user_id]
        user_profile = grpo_p_agent.user_profile
        
        # Calculate historical performance (simplified)
        historical_performance = {"grpo": 0.6, "grpo_p": 0.65}  # Default values
        
        # Get current hour
        current_hour = datetime.now().hour
        
        # Calculate session length (simplified - could track actual session)
        session_length = 30  # Default 30 minutes
        
        # Determine market volatility trend
        volatility_trend = "stable"
        if market_state.volatility > 0.6:
            volatility_trend = "increasing"
        elif market_state.volatility < 0.2:
            volatility_trend = "decreasing"
        
        # Calculate user engagement level (simplified)
        engagement_level = min(1.0, user_profile.total_interactions / 50.0)
        
        return ArbitrationContext(
            user_id=user.user_id,
            market_state=market_state,
            user_profile=user_profile,
            historical_performance=historical_performance,
            time_of_day=current_hour,
            session_length=session_length,
            market_volatility_trend=volatility_trend,
            user_engagement_level=engagement_level
        )
    
    def _generate_additional_recommendations(self, 
                                           user: SystemUser,
                                           market_state: MarketState,
                                           count: int) -> List[BlendedRecommendation]:
        """Generate additional recommendations with different strategies"""
        
        additional_recs = []
        grpo_p_agent = self.grpo_p_agents[user.user_id]
        
        for i in range(count):
            # Get alternative GRPO and GRPO-P recommendations
            # (In a real implementation, these would use different strategies/parameters)
            
            # Alternative GRPO recommendation
            alt_grpo_rec = self.grpo_population.get_consensus_recommendation(market_state)
            
            # Alternative GRPO-P recommendation (with more exploration)
            original_exploration = grpo_p_agent.exploration_rate
            grpo_p_agent.exploration_rate = min(0.8, original_exploration + 0.3)
            alt_grpo_p_rec = grpo_p_agent.get_action(market_state)
            grpo_p_agent.exploration_rate = original_exploration
            
            # Create alternative context with different parameters
            context = self._create_arbitration_context(user, market_state)
            
            # Use different arbitration strategy
            original_strategy = self.arbitration_controller.default_strategy
            from src.agents.arbitration_controller import BlendingStrategy
            alt_strategies = [s for s in BlendingStrategy if s != original_strategy]
            if alt_strategies:
                # Temporarily change strategy
                self.arbitration_controller.default_strategy = alt_strategies[i % len(alt_strategies)]
            
            alt_blended = self.arbitration_controller.arbitrate(
                alt_grpo_rec, alt_grpo_p_rec, context
            )
            # Enrich with item-level suggestions
            self._attach_item_level_recommendations(alt_blended)
            
            # Restore original strategy
            self.arbitration_controller.default_strategy = original_strategy
            
            additional_recs.append(alt_blended)
        
        return additional_recs

    def _attach_item_level_recommendations(self, recommendation: BlendedRecommendation, top_n: int = 3):
        """Attach item-level suggestions (e.g., companies/startups) to a sector-level recommendation."""
        try:
            if self.latest_processed_df is None or self.latest_processed_df.empty:
                return
            sector = recommendation.sector
            df = self.latest_processed_df
            sector_df = df[df.get('primary_sector') == sector].copy()
            if sector_df.empty:
                return
            # Compute a simple score: normalized business_sentiment + recency factor
            # Ensure published_datetime exists
            if 'published_datetime' not in sector_df.columns:
                sector_df['published_datetime'] = pd.to_datetime(sector_df.get('published_at'))
            # Normalize to tz-naive for subtraction
            sector_df['published_datetime'] = pd.to_datetime(sector_df['published_datetime'], utc=True, errors='coerce').dt.tz_convert(None)
            now = pd.Timestamp.utcnow().tz_localize(None)
            # Handle NaT
            sector_df['hours_ago'] = (now - sector_df['published_datetime']).dt.total_seconds() / 3600.0
            sector_df['hours_ago'] = sector_df['hours_ago'].fillna(sector_df['hours_ago'].max() or 24.0)
            # Normalize sentiment to 0..1
            sentiment = sector_df.get('business_sentiment', pd.Series([0.0] * len(sector_df), index=sector_df.index))
            sector_df['sent_norm'] = (sentiment.clip(-1, 1) + 1.0) / 2.0
            # Recency score (more recent is better)
            sector_df['recency_score'] = 1.0 / (1.0 + (sector_df['hours_ago'] / 12.0))
            sector_df['item_score'] = 0.7 * sector_df['sent_norm'] + 0.3 * sector_df['recency_score']

            # Extract candidate names from titles; fallback to source_name or trimmed title
            def extract_name(row):
                title = str(row.get('title', ''))
                source = str(row.get('source_name', ''))
                # Find capitalized multi-word sequences as proxy for company names
                candidates = re.findall(r"\b([A-Z][A-Za-z0-9&\-]+(?:\s+[A-Z][A-Za-z0-9&\-]+){0,3})\b", title)
                # Heuristic filter: exclude common words
                stop = {"The", "And", "For", "With", "This", "That", "A", "An"}
                candidates = [c for c in candidates if c.split()[0] not in stop]
                if candidates:
                    return candidates[0]
                if source:
                    return source
                # Fallback: first few words of title
                return title[:50] or sector.title()

            sector_df['item_name'] = sector_df.apply(extract_name, axis=1)

            # Aggregate by item_name (max score)
            grouped = sector_df.groupby('item_name')['item_score'].max().sort_values(ascending=False)
            top_items = grouped.head(top_n)

            recommendation.recommended_items = list(top_items.index)
            recommendation.item_scores = {name: float(score) for name, score in top_items.items()}
        except Exception as e:
            logger.error(f"Failed to attach item-level recommendations: {e}")
    
    def provide_feedback(self, 
                        user_id: str,
                        recommendation_id: str,
                        feedback_type: str,
                        feedback_score: float,
                        context: Optional[Dict[str, Any]] = None):
        """
        Provide user feedback on a recommendation
        
        Args:
            user_id: ID of the user providing feedback
            recommendation_id: ID of the recommendation being rated
            feedback_type: Type of feedback ("clicked", "saved", "rated", etc.)
            feedback_score: Score from -1 (negative) to 1 (positive)
            context: Additional context about the feedback
        """
        
        if user_id not in self.active_users:
            logger.error(f"User {user_id} not found")
            return
        
        # Create feedback object
        feedback = UserFeedback(
            user_id=user_id,
            recommendation_id=recommendation_id,
            action_taken=feedback_type,
            feedback_score=feedback_score,
            timestamp=datetime.now().isoformat(),
            context=context or {}
        )
        
        # Update GRPO-P agent with feedback
        grpo_p_agent = self.grpo_p_agents[user_id]
        
        # Find the recommendation in agent's history
        if grpo_p_agent.recommendation_history:
            last_action, timestamp = grpo_p_agent.recommendation_history[-1]
            # Simplified - in real implementation, would match by recommendation_id
            grpo_p_agent.update(self.latest_market_state, last_action, feedback)
        
        # Update arbitration controller
        self.arbitration_controller.update_performance(
            recommendation_id, feedback
        )
        
        logger.info(f"ðŸ“ Processed feedback from {user_id}: {feedback_type} ({feedback_score})")
    
    def get_system_stats(self) -> Dict[str, Any]:
        """Get comprehensive system statistics"""
        
        stats = {
            'system_info': {
                'active_users': len(self.active_users),
                'total_grpo_agents': len(self.grpo_population.agents) if self.grpo_population else 0,
                'latest_market_update': self.latest_market_state.timestamp if self.latest_market_state else None
            },
            'user_stats': {},
            'grpo_population_stats': {},
            'arbitration_stats': {}
        }
        
        # User statistics
        for user_id, user in self.active_users.items():
            if user_id in self.grpo_p_agents:
                agent_stats = self.grpo_p_agents[user_id].get_user_profile_summary()
                stats['user_stats'][user_id] = {
                    'role': user.role,
                    'sectors': user.sectors,
                    'risk_appetite': user.risk_appetite,
                    'agent_stats': agent_stats
                }
        
        # GRPO population statistics
        if self.grpo_population:
            stats['grpo_population_stats'] = self.grpo_population.get_population_stats()
        
        # Arbitration statistics
        if self.arbitration_controller:
            stats['arbitration_stats'] = self.arbitration_controller.get_arbitration_stats()
        
        # Market state
        if self.latest_market_state:
            stats['market_state'] = {
                'overall_sentiment': self.latest_market_state.overall_sentiment,
                'volatility': self.latest_market_state.volatility,
                'article_count': self.latest_market_state.article_count,
                'top_sectors': list(self.latest_market_state.sector_sentiments.keys())[:5],
                'trending_topics': list(self.latest_market_state.trending_topics.keys())[:5]
            }
        
        return stats
    
    def generate_system_report(self, user_id: Optional[str] = None) -> str:
        """Generate a comprehensive system report"""
        
        stats = self.get_system_stats()
        
        report = f"""
ðŸš€ HYBRID GRPO-GRPO-P RECOMMENDATION SYSTEM REPORT
{'='*60}

ðŸ“Š SYSTEM OVERVIEW:
â€¢ Active Users: {stats['system_info']['active_users']}
â€¢ GRPO Agents: {stats['system_info']['total_grpo_agents']}
â€¢ Last Market Update: {stats['system_info']['latest_market_update']}

ðŸ“ˆ MARKET STATE:
"""
        
        if 'market_state' in stats:
            market = stats['market_state']
            report += f"""
â€¢ Overall Sentiment: {market['overall_sentiment']:+.2f}
â€¢ Market Volatility: {market['volatility']:.2f}
â€¢ Articles Analyzed: {market['article_count']}
â€¢ Top Sectors: {', '.join(market['top_sectors'])}
â€¢ Trending Topics: {', '.join(market['trending_topics'])}
"""
        
        # User-specific report
        if user_id and user_id in stats['user_stats']:
            user_stats = stats['user_stats'][user_id]
            agent_stats = user_stats['agent_stats']
            
            report += f"""

ðŸ‘¤ USER PROFILE: {user_id}
{'â”€'*40}
â€¢ Role: {user_stats['role']}
â€¢ Sectors: {', '.join(user_stats['sectors'])}
â€¢ Risk Appetite: {user_stats['risk_appetite']}

ðŸ§  LEARNING PROGRESS:
â€¢ Total Interactions: {agent_stats['total_interactions']}
â€¢ Confidence Level: {agent_stats['confidence_level']:.1%}
â€¢ Success Rate: {agent_stats['success_rate']:.1%}
â€¢ Cold Start Mode: {"Yes" if agent_stats['is_cold_start'] else "No"}
â€¢ Exploration Rate: {agent_stats['exploration_rate']:.1%}

ðŸŽ¯ LEARNED PREFERENCES:
"""
            
            for sector, preference in agent_stats['sector_preferences'].items():
                report += f"â€¢ {sector.title()}: {preference:.2f}\n"
        
        # Population performance
        if 'grpo_population_stats' in stats and stats['grpo_population_stats']:
            pop_stats = stats['grpo_population_stats']
            report += f"""

ðŸ¤– GRPO POPULATION PERFORMANCE:
â€¢ Population Performance: {pop_stats.get('population_performance', 0):.2f}
â€¢ Active Agents: {pop_stats.get('active_agents', 0)}
â€¢ Best Agent: {pop_stats.get('best_agent_performance', 0):.2f}
â€¢ Performance Std: {pop_stats.get('performance_std', 0):.2f}
"""
        
        # Arbitration performance
        if 'arbitration_stats' in stats and stats['arbitration_stats']:
            arb_stats = stats['arbitration_stats']
            report += f"""

âš–ï¸ ARBITRATION PERFORMANCE:
â€¢ Total Recommendations: {arb_stats.get('total_recommendations', 0)}
â€¢ Exploration Rate: {arb_stats.get('exploration_rate', 0):.1%}

Strategy Performance:
"""
            
            for strategy, perf in arb_stats.get('strategy_performance', {}).items():
                report += f"â€¢ {strategy}: {perf.get('avg_performance', 0):.2f} ({perf.get('count', 0)} uses)\n"
        
        report += f"""

âœ… SYSTEM STATUS: OPERATIONAL
ðŸ“… Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        return report

    def _get_sector_keywords(self, sector: str) -> List[str]:
        """Get relevant keywords for a sector"""
        
        sector_keywords = {
            "finance": ["bank", "financial", "fintech", "payment", "insurance", "investment", "credit", "lending", "trading", "wealth", "asset"],
            "technology": ["tech", "software", "digital", "ai", "cloud", "cybersecurity", "startup", "innovation", "data", "platform", "app", "saas"],
            "energy": ["power", "energy", "renewable", "solar", "wind", "electric", "oil", "gas", "utilities", "grid", "battery", "ev"],
            "healthcare": ["health", "medical", "pharma", "biotech", "hospital", "clinic", "diagnostic", "treatment", "therapy", "drug", "device"],
            "retail": ["retail", "ecommerce", "shopping", "consumer", "marketplace", "store", "sales", "online", "digital", "customer"],
            "manufacturing": ["manufacturing", "industrial", "factory", "production", "machinery", "automation", "supply chain", "logistics"],
            "real_estate": ["real estate", "property", "construction", "housing", "development", "infrastructure", "commercial", "residential"]
        }
        
        return sector_keywords.get(sector.lower(), [sector.lower()])

# Example usage and testing
if __name__ == "__main__":
    print("ðŸš€ Testing Complete Hybrid Recommendation System")
    print("=" * 60)
    
    # Initialize system
    try:
        system = HybridRecommendationSystem()
        
        # Register test user
        test_user = SystemUser(
            user_id="entrepreneur_123",
            role="entrepreneur",
            sectors=["technology", "finance"],
            location="mumbai",
            capital_range="medium",
            risk_appetite="moderate",
            experience_level="intermediate",
            learning_mode=True,
            feedback_enabled=True,
            exploration_tolerance=0.4
        )
        
        user_id = system.register_user(test_user)
        print(f"âœ… Registered user: {user_id}")
        
        # Get recommendations
        recommendations = system.get_recommendations(user_id, max_recommendations=2)
        
        print(f"\nðŸ“Š Generated {len(recommendations)} recommendations:")
        for i, rec in enumerate(recommendations, 1):
            print(f"\n{i}. {rec.sector.title()} - {rec.recommendation_type.upper()}")
            print(f"   Confidence: {rec.confidence:.1%}")
            print(f"   GRPO Weight: {rec.grpo_weight:.1%}")
            print(f"   GRPO-P Weight: {rec.grpo_p_weight:.1%}")
            print(f"   Strategy: {rec.blending_strategy}")
        
        # Simulate feedback
        system.provide_feedback(
            user_id=user_id,
            recommendation_id="rec_1",
            feedback_type="clicked",
            feedback_score=0.8
        )
        print(f"\nâœ… Provided positive feedback")
        
        # Generate report
        report = system.generate_system_report(user_id)
        print(f"\nðŸ“‹ SYSTEM REPORT:")
        print(report)
        
        print("\nðŸŽ‰ Complete Hybrid System Test Successful!")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
